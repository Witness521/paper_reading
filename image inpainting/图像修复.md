GAN在图像修复过程中的缺陷：

<img src="H:\files\python_file\paper_reading\image inpainting\pic\image-20220914213119722.png" alt="image-20220914213119722" style="zoom:67%;" />

<img src="H:\files\python_file\paper_reading\image inpainting\pic\image-20220914213300754.png" alt="image-20220914213300754" style="zoom:67%;" />

提出的改进方法/模型： from 研究生论文 赵立怡 明天继续

1. 将非监督学习的GAN和监督学习的CNN进行结合成为DCGAN（深度卷积生成式对抗网络）-- 效果一般

​    DCGAN中所有的池化层使用卷积层替换，**生成器模型**中使用转置卷积（反卷积）替换最大池化层，**判别器模型**中使用步幅卷积(strided convolution)替换最大池化层

<img src="H:\files\python_file\paper_reading\image inpainting\pic\image-20220914214621061.png" alt="image-20220914214621061" style="zoom:80%;" />



2. Wasserstein 生成式对抗网络(WGAN)

   WGAN解决了GAN的三点问题：

- 解决了生成式对抗网络训练不稳定，生成器、判别器的训练程度无法准确衡量的问题。
- 解决了训练崩溃(collapse mode)问题，保证生成样本的多样性。
- 解决了训练过程中没有确切的目标函数指示网络训练进程的问题。设定目标函数越小表示网络训练程度越好，生成器生成的图像更加清晰逼真。

WGAN相对于GAN做的改进

(1)生成器、判别器的目标函数根据 Wasserstein 距离原理不再取 log；

(2)判别器最后一层去掉 Sigmoid 函数；

(3)每次更新判别器网络后，参数范围重置为 $w\in[-c,c]$
(4)更改基于动量的优化算法 Adam 为 RMSProp。