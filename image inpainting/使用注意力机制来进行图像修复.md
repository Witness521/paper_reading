### DeepFill v1 (Generative Image Inpainting with Contextual Attention)

**使用上下文注意力机制来进行深度图像修复**  [解读链接](https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg==&mid=2247494431&idx=1&sn=4556be2eb7d239e198f197e76d1761d0&chksm=c06a6342f71dea543422c787aa5a061b7bdba4a295923dab405a69fa53c1f10cffd2819d86d3&scene=21#wechat_redirect)

​    熟悉CNN的人应该知道，在卷积层，核的大小和膨胀率控制着感受野，网络需要越深入，才能看到整个输入图像。这意味着，如果我们想捕捉图像的上下文，我们必须依赖于更深的层次，但我们丢失了空间信息，因为更深层次的特征的空间大小总是更小。因此，我们必须找到一种方法，在不用太加深网络的情况下，从遥远的空间位置借用信息(即理解图像的上下文)。

![DeepFillv1.png](pic\DeepFillv1.png)

对于该体系结构，所提出的框架由两个生成器网络和两个判别器网络组成。这两个生成器在全卷积网络的基础上使用了**膨胀卷积**。一个生成器用于**粗重建**，另一个用于**细化**。这被称为标准的从粗到细的网络结构。这两个判别器同时在全局和局部看完整的图像。**全局判别器**以整个图像作为输入，而**局部判别器**以填充区域作为输入。



<img src="pic\空间注意力机制.png" alt="image-20220918115714664" style="zoom:70%;" />

​    以图4为例，生成的缺失区域内的特征大小为64×64×64，假设缺失区域外的特征分为128个小特征patch，大小为64×3×3。注意，本例中特征的通道大小是64。然后，我们将128个小的feature patch与缺失区域内生成的feature进行卷积，得到大小为**128×64×64**的feature map。其反映了128个patch对该位置的贡献，然后再进行Softmax归一化操作。

*与上一篇文章中提到的Shift-Net相比，你可以看到，这一次我们给每个已知特征的patch分配了权重，来表示重建的时候每个特征位置对于缺失区域的重要性（软分配），而不是对于缺失区域的每个位置找一个最相似的（硬分配）。这也是为什么提出的上下文注意力是可微的。*

**注意力传播**

注意力传播可以看作是注意特征图的微调。这里的关键思想是，**邻近的像素通常有更接近的像素值**。这意味着他们会考虑周围环境的注意力值来调整每个注意力分数。

![图片](https://mmbiz.qpic.cn/mmbiz_png/KYSDTmOVZvq9W45NyCMekglwCTBibG8vQAPVypH3ZzUlgPtwb8PUtbN3NFKLC5zVR3hiahPmiaToESHNeVCDWGx9g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

例如，如果我们考虑左邻居和右邻居的注意力值，我们可以使用上面列出的公式更新当前的注意力值。注意，*k*控制要考虑的邻居的数量。作者声称，这可以进一步提高修复结果，这也可以通过与单位矩阵卷积作为核来实现。

关于注意力机制的另一点是，采用了两种技术来控制提取的已知特征块的数量。

i) 以较大的步长提取已知的特征patch，以减少kernel数量。

ii) 操作前先对特征图大小进行向下采样，获取注意力图后再进行上采样。



**将注意力机制引入网络**

<img src="https://mmbiz.qpic.cn/mmbiz_png/KYSDTmOVZvq9W45NyCMekglwCTBibG8vQG5wNcerSh3yzK7LKrktXZstknw0j4EeJ9wEGjKKeaV61lniaEvB8Ozg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

在细化网络中嵌入上下文注意力机制



### Interactive Image Inpainting Using Semantic Guidance (师兄的那篇)

<img src="pic\师兄network.png" alt="image-20220919195814805" style="zoom:80%;" />

此篇论文中，ESPA Module使用的是外部空间注意力机制(**External Spatial Attetion Module**)，与DeepFill v1**相同点**都是将注意力机制的模块和扩张卷积并行，整合上下文和damaged图像的编码特征，以计算他们之间的长范围依赖。**不同点**是ESPA模块利用两个外部可学习的Key和Value分别与输入query在H维和W维度上相乘以实现空间信息的传播。





### 在图像上的Attention机制（整理）

注意力机制的本质就是定位到感兴趣的信息，抑制无用信息，结果通常都是以概率图或者概率特征向量的形式展示，从原理上来说，主要分为空间注意力模型，[通道](https://so.csdn.net/so/search?q=通道&spm=1001.2101.3001.7020)注意力模型，空间和通道混合注意力模型三种，这里不区分soft和hard attention。 [链接](https://blog.csdn.net/Vodka_Lou/article/details/115671748)

#### 1. 空间注意力模型(spatial attention)

  在二维平面上，对H x W尺寸的特征图学习到一个权重矩阵，对应每个像素都会学习到一个权重。而这些**权重**代表的就是**某个空间位置信息的重要程度** ，将该空间注意力矩阵附加在原来的特征图上，增大有用的特征，弱化无用特征，从而起到特征筛选和增强的效果。代表的Self-Attention、Non-local Attention以及Spatial Transformer等。

- ##### Self-Attention （自注意力机制）

(1) 第一步是将query和每个key进行相似度计算得到权重，常用的相似度函数有点积，拼接，感知机等；

(2) 第二步一般是使用一个softmax函数对这些权重进行归一化，转换为注意力；

(3) 第三步将权重和相应的键值value进行加权求和得到最后的attention。

<img src="pic\selfAttention.png" alt="image-20220920110348618" style="zoom:80%;" />

- **Non-local Attention（非局部注意力）**

  CNN中的卷积单元每次只关注邻域kernel size 的区域，就算后期感受野越来越大，终究还是局部区域的运算，这样就忽略了全局其他片区（比如很远的像素）对当前区域的贡献。所以Non-local blocks 要做的是，捕获这种**long-range** 关系：对于2D图像，就是图像中任何像素对当前像素的关系权值；对于3D视频，就是所有帧中的所有像素，对当前帧的像素的关系权值。

<img src="https://img-blog.csdnimg.cn/img_convert/a1268f85ba2cd7df15a5c22275e42945.png" alt="img" style="zoom:80%;" />

#### 2. 通道注意力模型（channel Attention）

​    不同于空间注意力机制给每一个像素都学习到一个权重，通道注意力给每个**通道(channel)**上的特征图学习一个**权重**，代表该通道与关键信息的相似度。在神经网络中，feature map尺寸越小，channel数量越多，这时如果用一个通道注意力告诉该网络哪些是重要的，往往能起到很好的效果，这时CV领域做通道注意力往往比空间好的一个原因。代表的是SENet、SKNet、ECANet等。

- **SENet** [知乎链接](https://zhuanlan.zhihu.com/p/32702350)

  对于卷积操作，很大一部分工作是提高感受野，即空间上融合更多特征融合，或者是提取多尺度空间信息。而SENet网络的创新点在于关注**channel之间的关系**，希望模型可以自动学习到不同channel特征的重要程度。为此，SENet提出了Squeeze-and-Excitation (SE)模块

![img](https://pic1.zhimg.com/80/v2-eb33a772a6029e5c8011a5ab77ea2f74_720w.jpg)

图中的$F_{tr}$ 是传统的卷积结构，SENet增加的是U后的内容，对U先做一个**全局平均池化**（文中称为squeeze），输出的1x1xC数据再经过**两个全连接层**（文中称为Excitation），最后用**sigmoid**（文中称为self-gating mechanism）把这个值作为scale乘到U的C个通道上，作为下一级的输入数据。

SENet是在channel维度上做attention或者gating操作，这种注意力机制可以让模型关注信息量最大的channel特征，而抑制那些不重要的channel特征

在Excitation中，为了降低模型复杂度以及提升泛化能力，这里采用包含两个全连接层的bottleneck结构，其中第一个FC层起到降维的作用，降维系数为r是个超参数，然后采用ReLU激活。最后的FC层恢复原始的维度。

<img src="https://pic3.zhimg.com/80/v2-8515d83936b780c200f62caf9ee37212_720w.jpg" alt="img" style="zoom:80%;" />

模型可以嵌入到Inception和ResNet中



- **SKNet**

SKNet是基于SENet的改进，他的思路是在提高精度。

![img](https://img-blog.csdnimg.cn/img_convert/80b5d3fce7ede2e32116439c1d4a398b.png)

上图所示是SKNet的基本结构。主要创新点是设置了一组动态选择的卷积，分为三个部分操作Split、Fuse、Select。

（1）Split：对输入向量X进行不同卷积核大小的完整卷积操作（组卷积），特别地，为了进一步提升效率，将5x5的传统卷积替代为dilation=2，卷积核为3x3的空洞卷积；

（2）Fuse：类似SE模块的处理，两个feature map相加后，进行全局平均池化操作，全连接先降维再升维的为两层全连接层，输出的两个注意力系数向量a和b，其中a+b=1；

（3）Select：Select操作对应于SE模块中的Scale。Select使用a和b两个权重矩阵对之前的两个feature map进行加权操作，它们之间有一个类似于特征挑选的操作。



#### 3. 混合域注意力方法

空间注意力和通道注意力结合，根据DL任务的不同，它们结合方式也存在区别，有代表性的是CBAM、DANet、CCNet、Residual Attention等

- **CBAM**（效果很不错）

<img src="https://img-blog.csdnimg.cn/img_convert/2321e58816ef41db554721667f22a022.png" alt="img" style="zoom:80%;" />

CBDM的基本结构，前面使用SEnet的通道注意力模块，后面的注意力模块设计也参考了SENet，它将全局平均池化用在了通道上，因此作用后就得到了一个二维的空间注意力系数矩阵。CBAM在通道与空间上同时做全局平均和全局最大的混合Pooling，能提取到更多有效信息。

作者将注意力过程分为两个独立的部分，通道注意力模块和空间注意力模块。这样不仅可以节约参数和计算力，而且保证了其可以作为即插即用的模块集成到现有的网络架构中去。

1. **通道的注意力模块(Channel Attention Module)**

<img src="https://pic2.zhimg.com/80/v2-8fefab2340c4a045f77ad35501717e89_720w.jpg" alt="img" style="zoom:80%;" />

如上图所示，输入是一个 H×W×C 的特征 F，我们先分别进行一个空间的全局平均池化和最大池化得到两个 1×1×C 的通道描述。接着，再将它们分别送入一个两层的神经网络，第一层神经元个数为 C/r，激活函数为 Relu，第二层神经元个数为 C。注意，这个两层的神经网络是共享的。

然后，再将得到的两个特征相加后经过一个 Sigmoid 激活函数得到权重系数 Mc。最后，拿权重系数和原来的特征 F 相乘即可得到缩放后的新特征。

2. **空间注意力模块**

<img src="https://pic3.zhimg.com/80/v2-e2b0976b0ed30ad554abfd80a912407a_720w.jpg" alt="img" style="zoom:80%;" />

与通道注意力相似，给定一个 H×W×C 的特征 F‘，我们先分别进行一个通道维度的平均池化和最大池化得到两个 H×W×1 的通道描述，并将这两个描述按照通道拼接在一起。然后，经过一个 7×7 的卷积层（此处应该是same卷积，即卷积完特征图的大小不变），激活函数为 Sigmoid，得到权重系数Ms。最后，拿权重系数和特征 F’ 相乘即可得到缩放后的新特征。

<img src="https://pic3.zhimg.com/80/v2-c023d0d068bca35204040fe4025471da_720w.jpg" alt="img" style="zoom:80%;" />

最后将通道注意力和空间注意力采用顺序的方式存放。





