# 图像修复论文阅读

### Image Inpainting Guided by Coherence Priors of Semantics and Textures(2021CVPR)

一、 文章的主要贡献：

1. 引入相关先验(coherence priors)来突出图像嵌入过程中语义和纹理之间的相互一致性，设计两种相关损失(coherence loss)提高语义信息和修复图像在全局结构层和局部纹理层的一致性。
2. 提出了一种新的语义注意传播模块，该模块通过捕获遥远的关系并在特征图中引用相同语义的纹理特征来生成语义真实感纹理。

二、 提出的一致性损失(Coherence Loss)

<img src="pic\image-20221009173901382.png" alt="image-20221009173901382" style="zoom:67%;" />

1.  non-local patch coherence loss

​		促进在与真实图像中任何已知的具有相同语义的patch类似，将根据语义生成的patch和real image中的patch进行计算相似度(affinity)。

2. structure coherence loss

​		结构一致性损失确保了整个语义分割图与修复图像之间的结构一致性，在这个部分使用两个条件判别器$D_t和D_s$ 来判断语义分割图(segmentation map)和修复图像(inpainted image)的真实性。

三、 整体的网络结构：

<img src="pic\image-20221009155204447.png" alt="image-20221009155204447" style="zoom:80%;" />

​		此篇文章最大的改进就是将deepfill v1中的注意力机制方法加上了一个语义分割的方法，通过分割不同的物体(例如：building、tree)进行修复，然后再将各个修复后的物体进行叠加就可得到整体修复的图像（前景），再和背景进行叠加输入到扩张卷积中就得到了decoder出的图像。

​		目前现有的注意力模块引用的是整个已知区域，没有任何的语义引导，所以通常会将错误的纹理patch匹配到缺失区域，导致纹理模糊。**SWAP**的方法则是匹配同一语义类中的patch，有效提高了匹配纹理的保真度，从而产生更有效的纹理。



搭一个图像修复的baseline模型，使用UNet结构 [旷世微信公众号](https://mp.weixin.qq.com/s/WmpmIV8Q45T0GvKI487pwg)



### Guidance and Evaluation: Semantic-Aware Image Inpainting for Mixed Scenes

​		武汉大学第二篇 文章定位在**混合场景**下的语义感知图像修复

<img src="pic\image-20221011165826105.png" alt="image-20221011165826105" style="zoom:80%;" />

​		其中SCEM的作用机制是：其中$S_{l}$ 是k个通道的概率图，每个通道中的像素展示了其和特定类的相似程度，然后经过一个逐像素的最大池化层（其中值小的就判断为假）。threshold由排序置信值的百分位决定。



### Coherent Semantic Attention for Image Inpainting

coherent semantic attention (**CSA**)

<img src="pic\image-20221012092734356.png" alt="image-20221012092734356" style="zoom:80%;" />

$D_{max_{i}}$ 代表$m_i$ 和上下文区域中最相似的patch $\overline{m_i}$ 的相似性，$Dad_i$ 代表两个相邻生成patch之间的相似性

<img src="pic\image-20221012100523425.png" alt="image-20221012100523425" style="zoom:80%;" />

**Searching过程**：先抽取$\overline{m_i}$ 中的patch，将其变成卷积filter，然后和$m$进行卷积运算，对于每一个$m_i$ 使用最相似的 $\overline{m_i}$ 进行初始化，并赋予$D_{max_{i}}$ 用于下一个操作。

**Generating过程**：使用$\overline{m_i}$ 和$m_{i-1}$ 生成$m_i$ 

<img src="pic\image-20221012101844891.png" alt="image-20221012101844891" style="zoom:60%;" />

每个mi包含mi和m1 ~ i−1的信息，当我们计算mi和mi−1之间的Dadi时，都考虑了mi和m1 ~ i−1之间的相关性。

<img src="pic\image-20221012104733245.png" alt="image-20221012104733245" style="zoom:80%;" />



